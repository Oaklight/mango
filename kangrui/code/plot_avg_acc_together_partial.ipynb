{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84db5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colors import COLOR_MAP\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87f0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PLOT_DIR = \"../plots\"\n",
    "if not os.path.exists(PLOT_DIR):\n",
    "    os.makedirs(PLOT_DIR)\n",
    "\n",
    "# Define the global fontsize\n",
    "GLOBAL_FONTSIZE = 40\n",
    "\n",
    "models=[\"RWKV\",\"RWKV-S\",\"LLaMa\",\"LLaMa-S\",\"LLaMa2\",\"LLaMa2-S\",\"GPT-3.5\",\"GPT-4\"]\n",
    "\n",
    "dir_dict={\n",
    "    \"RWKV\":'/share/data/mei-work/kangrui/github/mango/kangrui/eval_results/results_rmkv_overall_0713/rwkv',\n",
    "    \"RWKV-S\":''\n",
    "}\n",
    "# Dummy data for model names\n",
    "model_names = {\n",
    "    \"model1\": \"RWKV\",\n",
    "    \"model2\": \"RWKV-S\",\n",
    "    \"model3\": \"LLaMa\",\n",
    "    \"model4\": \"LLaMa-S\",\n",
    "    \"model5\": \"GPT-3.5\",\n",
    "    \"model6\": \"GPT-4\",\n",
    "}\n",
    "\n",
    "# # Define the score dictionaries\n",
    "# avg_acc_df_easy_success = {\n",
    "#     \"model1\": 0.0179617337,\n",
    "#     \"model2\": 0.02509147935,\n",
    "#     \"model3\": 0.5479930192,\n",
    "#     \"model4\": 0.3269174686,\n",
    "#     \"model5\": 0.4330339711,\n",
    "#     \"model6\": 0.7708535142,\n",
    "# }\n",
    "\n",
    "# avg_acc_df_hard_success = {\n",
    "#     \"model1\": 0.01574150787,\n",
    "#     \"model2\": 0.02050113895,\n",
    "#     \"model3\": 0.1739130435,\n",
    "#     \"model4\": 0.09378531073,\n",
    "#     \"model5\": 0.1445643793,\n",
    "#     \"model6\": 0.4235085647,\n",
    "# }\n",
    "\n",
    "# avg_acc_df_easy_reasoning = {\n",
    "#     \"model1\": 0.0007809449434,\n",
    "#     \"model2\": 0.0005227391532,\n",
    "#     \"model3\": 0.4537521815,\n",
    "#     \"model4\": 0.2621755614,\n",
    "#     \"model5\": 0.2806195497,\n",
    "#     \"model6\": 0.6662361425,\n",
    "# }\n",
    "\n",
    "# avg_acc_df_hard_reasoning = {\n",
    "#     \"model1\": 0,\n",
    "#     \"model2\": 0,\n",
    "#     \"model3\": 0.1666666667,\n",
    "#     \"model4\": 0.05649717514,\n",
    "#     \"model5\": 0.04780262143,\n",
    "#     \"model6\": 0.2926757236,\n",
    "# }\n",
    "\n",
    "avg_acc_df_easy_success = {\n",
    "    \"model1\": 0.1874576315,  # RWKV\n",
    "    \"model2\": 0.19754977,    # RWKV-S\n",
    "    \"model3\": 0.6494218881,  # LLaMa\n",
    "    \"model4\": 0.4791872965,  # LLaMa-S\n",
    "    \"model5\": 0.5725752147,  # GPT-3.5\n",
    "    \"model6\": 0.8299931432,  # GPT-4\n",
    "}\n",
    "\n",
    "avg_acc_df_hard_success = {\n",
    "    \"model1\": 0.2000283175,  # RWKV\n",
    "    \"model2\": 0.2000834802,  # RWKV-S\n",
    "    \"model3\": 0.3421988836,  # LLaMa\n",
    "    \"model4\": 0.2684909455,  # LLaMa-S\n",
    "    \"model5\": 0.3214162987,  # GPT-3.5\n",
    "    \"model6\": 0.5750770214,  # GPT-4\n",
    "}\n",
    "\n",
    "avg_acc_df_easy_reasoning = {\n",
    "    \"model1\": 0.0007809449434,  # RWKV\n",
    "    \"model2\": 0.0005227391532,  # RWKV-S\n",
    "    \"model3\": 0.4537521815,     # LLaMa\n",
    "    \"model4\": 0.2621755614,     # LLaMa-S\n",
    "    \"model5\": 0.2806195497,     # GPT-3.5\n",
    "    \"model6\": 0.6662361425,     # GPT-4\n",
    "}\n",
    "\n",
    "avg_acc_df_hard_reasoning = {\n",
    "    \"model1\": 0,              # RWKV\n",
    "    \"model2\": 0,              # RWKV-S\n",
    "    \"model3\": 0.1666666667,   # LLaMa\n",
    "    \"model4\": 0.05649717514,  # LLaMa-S\n",
    "    \"model5\": 0.04780262143,  # GPT-3.5\n",
    "    \"model6\": 0.2926757236,   # GPT-4\n",
    "}\n",
    "\n",
    "\n",
    "# avg_acc_rf_easy_success = {\n",
    "#     \"model1\": 0.0006626905235,\n",
    "#     \"model2\": 0.00205338809,\n",
    "#     \"model3\": 0.2005420054,\n",
    "#     \"model4\": 0.1438492063,\n",
    "#     \"model5\": 0.1510318949,\n",
    "#     \"model6\": 0.5448717949,\n",
    "# }\n",
    "\n",
    "# avg_acc_rf_hard_success = {\n",
    "#     \"model1\": 0,\n",
    "#     \"model2\": 0,\n",
    "#     \"model3\": 0.01515151515,\n",
    "#     \"model4\": 0.01098901099,\n",
    "#     \"model5\": 0.02527283171,\n",
    "#     \"model6\": 0.448372093,\n",
    "# }\n",
    "\n",
    "# avg_acc_rf_easy_reasoning = {\n",
    "#     \"model1\": 0,\n",
    "#     \"model2\": 0,\n",
    "#     \"model3\": 0.1924119241,\n",
    "#     \"model4\": 0.1354166667,\n",
    "#     \"model5\": 0.1438398999,\n",
    "#     \"model6\": 0.5239049145,\n",
    "# }\n",
    "\n",
    "# avg_acc_rf_hard_reasoning = {\n",
    "#     \"model1\": 0,\n",
    "#     \"model2\": 0,\n",
    "#     \"model3\": 0.01515151515,\n",
    "#     \"model4\": 0.006593406593,\n",
    "#     \"model5\": 0.02297530155,\n",
    "#     \"model6\": 0.4223255814,\n",
    "# }\n",
    "\n",
    "# Define the score dictionaries for RF\n",
    "avg_acc_rf_easy_success = {\n",
    "    \"model1\": 0,                    # RWKV\n",
    "    \"model2\": 0.004106776181,       # RWKV-S\n",
    "    \"model3\": 0.2032520325,         # LLaMa\n",
    "    \"model4\": 0.1438492063,         # LLaMa-S\n",
    "    \"model5\": 0.1511882427,         # GPT-3.5\n",
    "    \"model6\": 0.5454059829,         # GPT-4\n",
    "}\n",
    "\n",
    "avg_acc_rf_hard_success = {\n",
    "    \"model1\": 0.007289595759,       # RWKV\n",
    "    \"model2\": 0,                    # RWKV-S\n",
    "    \"model3\": 0.01515151515,        # LLaMa\n",
    "    \"model4\": 0.01098901099,        # LLaMa-S\n",
    "    \"model5\": 0.02527283171,        # GPT-3.5\n",
    "    \"model6\": 0.4502325581,         # GPT-4\n",
    "}\n",
    "\n",
    "avg_acc_rf_easy_reasoning = {\n",
    "    \"model1\": 0,                    # RWKV\n",
    "    \"model2\": 0,                    # RWKV-S\n",
    "    \"model3\": 0.1924119241,         # LLaMa\n",
    "    \"model4\": 0.1354166667,         # LLaMa-S\n",
    "    \"model5\": 0.1438398999,         # GPT-3.5\n",
    "    \"model6\": 0.5239049145,         # GPT-4\n",
    "}\n",
    "\n",
    "avg_acc_rf_hard_reasoning = {\n",
    "    \"model1\": 0,                    # RWKV\n",
    "    \"model2\": 0,                    # RWKV-S\n",
    "    \"model3\": 0.01515151515,        # LLaMa\n",
    "    \"model4\": 0.006593406593,       # LLaMa-S\n",
    "    \"model5\": 0.02297530155,        # GPT-3.5\n",
    "    \"model6\": 0.4223255814,         # GPT-4\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# all_scores = [avg_acc_desti_nice, avg_acc_desti_harsh, avg_acc_route_nice, avg_acc_route_harsh]\n",
    "all_scores = {\n",
    "    \"avg_acc_rf_easy_success\": avg_acc_rf_easy_success,\n",
    "    \"avg_acc_rf_easy_reasoning\": avg_acc_rf_easy_reasoning,\n",
    "    \"avg_acc_rf_hard_success\": avg_acc_rf_hard_success,\n",
    "    \"avg_acc_rf_hard_reasoning\": avg_acc_rf_hard_reasoning,\n",
    "    \"avg_acc_df_easy_success\": avg_acc_df_easy_success,\n",
    "    \"avg_acc_df_easy_reasoning\": avg_acc_df_easy_reasoning,\n",
    "    \"avg_acc_df_hard_success\": avg_acc_df_hard_success,\n",
    "    \"avg_acc_df_hard_reasoning\": avg_acc_df_hard_reasoning,\n",
    "}\n",
    "\n",
    "\n",
    "# Set the y range\n",
    "y_range = (0, 1)\n",
    "\n",
    "# Please adapt this above commented code to 4 separate plot, no subplot:\n",
    "# 1. avg_acc_route_nice\n",
    "# 2. avg_acc_route_harsh\n",
    "# 3. avg_acc_desti_nice\n",
    "# 4. avg_acc_desti_harsh\n",
    "\n",
    "# Create the bar plot\n",
    "for name, each in all_scores.items():\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    colors = [COLOR_MAP[model_names[model_name]] for model_name in model_names]\n",
    "    plt.bar(\n",
    "        list(model_names.values()),\n",
    "        [each[model_name] for model_name in model_names],\n",
    "        color=colors,\n",
    "    )\n",
    "    # Set the y range\n",
    "    plt.ylim(y_range)\n",
    "    plt.yticks(fontsize=GLOBAL_FONTSIZE)\n",
    "    plt.xticks(fontsize=GLOBAL_FONTSIZE, rotation=45)\n",
    "    if name.endswith('reasoning'):\n",
    "        plt.ylabel('Reasoning Accuracy',fontsize=GLOBAL_FONTSIZE+5)\n",
    "    else:\n",
    "        plt.ylabel('Success Rate',fontsize=GLOBAL_FONTSIZE+5)\n",
    "    # horizontal line at y=0.8\n",
    "    plt.axhline(y=0.2, color=\"lightcoral\", linestyle=\"--\")\n",
    "    plt.axhline(y=0.4, color=\"lightcoral\", linestyle=\"--\")\n",
    "    plt.axhline(y=0.6, color=\"lightcoral\", linestyle=\"--\")\n",
    "    plt.axhline(y=0.8, color=\"lightcoral\", linestyle=\"--\")\n",
    "\n",
    "    # save\n",
    "    plt.savefig(f\"{PLOT_DIR}/{name}_partial.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4cffc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mango",
   "language": "python",
   "name": "mango"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
