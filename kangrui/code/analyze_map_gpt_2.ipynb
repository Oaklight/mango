{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f733bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import networkx as nx\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.map_utils import get_game_info_with_G_eval\n",
    "from utils.map_utils_old import find_all_paths\n",
    "from utils.clean_utils import compute_hash_for_path\n",
    "import tiktoken\n",
    "import openai\n",
    "import time\n",
    "import traceback\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e4bbf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cut_off_and_walkthrough_text(walkthrough:str,token_size_limit=3600,model_name='gpt-4'):\n",
    "    encoder = tiktoken.encoding_for_model(model_name)\n",
    "    enc = encoder.encode(walkthrough)\n",
    "    if len(enc) > token_size_limit:\n",
    "        cut_off_walkthrough_text = encoder.decode(enc[:token_size_limit])\n",
    "    else:\n",
    "        cut_off_walkthrough_text = encoder.decode(enc)\n",
    "    cut_off_number = int(cut_off_walkthrough_text.split('NUM: ')[-2].split('\\n')[0])\n",
    "    if cut_off_number > 70:\n",
    "        cut_off_number = 70\n",
    "\n",
    "    walkthrough_text = walkthrough.split('NUM: {}'.format(cut_off_number + 1))[0]\n",
    "\n",
    "    return cut_off_number,len(encoder.encode(walkthrough_text))\n",
    "\n",
    "def normalized_edit_distance(s1, s2):\n",
    "    s1 = s1.lower()\n",
    "    s2 = s2.lower()\n",
    "    \n",
    "    s1=s1.split()\n",
    "    s2=s2.split()\n",
    "    \n",
    "    m = len(s1) + 1\n",
    "    n = len(s2) + 1\n",
    "\n",
    "    dp = [[0] * n for _ in range(m)]\n",
    "\n",
    "    for i in range(m):\n",
    "        dp[i][0] = i\n",
    "\n",
    "    for j in range(n):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = min(\n",
    "                    dp[i - 1][j] + 1,  # deletion\n",
    "                    dp[i][j - 1] + 1,  # insertion\n",
    "                    dp[i - 1][j - 1] + 1  # substitution\n",
    "                )\n",
    "    \n",
    "    # Compute the normalized score\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    score = 1 - dp[m - 1][n - 1] / max_len\n",
    "    return score\n",
    "\n",
    "def get_edegs(G):\n",
    "    edges=[]\n",
    "    for edge in G.edges(data=True):\n",
    "        edges.append(edge)\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ca0a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_locations(G,cut_off_number):\n",
    "    edges=get_edegs(G)\n",
    "    locations=set()\n",
    "    for edge in edges:\n",
    "        if edge[2]['step_min_cutoff']<=cut_off_number:\n",
    "            locations.add(edge[0])\n",
    "            locations.add(edge[1])\n",
    "    return len(locations)\n",
    "\n",
    "def num_of_exp_edges(G,cut_off_number):\n",
    "    edges=get_edegs(G)\n",
    "    cnt=0\n",
    "    for edge in edges:\n",
    "        if edge[2]['step_min_cutoff']<=cut_off_number and edge[2]['seen_in_forward']:\n",
    "            cnt+=1         \n",
    "    return cnt\n",
    "\n",
    "def num_of_imp_edges(G,cut_off_number):\n",
    "    edges=get_edegs(G)\n",
    "    cnt=0\n",
    "    for edge in edges:\n",
    "        if edge[2]['step_min_cutoff']<=cut_off_number and (not edge[2]['seen_in_forward']):\n",
    "            cnt+=1         \n",
    "    return cnt\n",
    "\n",
    "def ratio_of_conf_locations(G,all2all,cut_off_number):\n",
    "    edges=get_edegs(G)\n",
    "    locations=set()\n",
    "    for edge in edges:\n",
    "        if edge[2]['step_min_cutoff']<=cut_off_number:\n",
    "            locations.add(edge[0])\n",
    "            locations.add(edge[1])\n",
    "    locations=list(locations)\n",
    "    \n",
    "    score=0\n",
    "    for i in range(len(locations)):\n",
    "        current_max_score = float('-inf')\n",
    "        for j in range(len(locations)):\n",
    "            if i != j:  # Don't compare an item with itself\n",
    "                current_score = normalized_edit_distance(locations[i], locations[j])\n",
    "                if current_score > current_max_score:\n",
    "                    current_max_score = current_score\n",
    "        score+=current_max_score\n",
    "        \n",
    "    return score/len(locations) if len(locations)>0 else 0\n",
    "\n",
    "def num_of_conf_locations(G,all2all,cut_off_number):\n",
    "    edges=get_edegs(G)\n",
    "    locations=set()\n",
    "    for edge in edges:\n",
    "        if edge[2]['step_min_cutoff']<=cut_off_number:\n",
    "            locations.add(edge[0])\n",
    "            locations.add(edge[1])\n",
    "    locations=list(locations)\n",
    "    \n",
    "    score=0\n",
    "    for i in range(len(locations)):\n",
    "        current_max_score = float('-inf')\n",
    "        for j in range(len(locations)):\n",
    "            if i != j:  # Don't compare an item with itself\n",
    "                current_score = normalized_edit_distance(locations[i], locations[j])\n",
    "                if current_score > current_max_score:\n",
    "                    current_max_score = current_score\n",
    "        score+=current_max_score\n",
    "        \n",
    "    return score\n",
    "    \n",
    "    \n",
    "\n",
    "def average_length_of_all2all(all2all,cut_off_number):\n",
    "    length=0\n",
    "    cnt=0\n",
    "    for path in all2all:\n",
    "        if path['path_min_cutoff']<=cut_off_number:\n",
    "            length+=path['step_count']\n",
    "            cnt+=1\n",
    "    return length/cnt if cnt>0 else 0\n",
    "\n",
    "def average_length_of_all2all_simple(all2all,cut_off_number):\n",
    "    length=0\n",
    "    cnt=0\n",
    "    for path in all2all:\n",
    "        if path['path_min_cutoff']<=cut_off_number and path['all_steps_seen_in_forward']:\n",
    "            length+=path['step_count']\n",
    "            cnt+=1\n",
    "    return length/cnt if cnt>0 else 0\n",
    "\n",
    "def average_length_of_all2all_hard(all2all,cut_off_number):\n",
    "    length=0\n",
    "    cnt=0\n",
    "    for path in all2all:\n",
    "        if path['path_min_cutoff']<=cut_off_number and not path['all_steps_seen_in_forward']:\n",
    "            length+=path['step_count']\n",
    "            cnt+=1\n",
    "    return length/cnt if cnt>0 else 0\n",
    "        \n",
    "def average_num_of_imp_edge(all2all,cut_off_number):\n",
    "    num=0\n",
    "    cnt=0\n",
    "    for path in all2all:\n",
    "        if path['path_min_cutoff']<=cut_off_number and not path['all_steps_seen_in_forward']:\n",
    "            cnt+=1\n",
    "            for edge in path[\"path_details\"]:\n",
    "                if not edge[\"seen_in_forward\"]:\n",
    "                    num+=1\n",
    "                    \n",
    "    return num/cnt if cnt>0 else 0\n",
    "\n",
    "def num_of_special_moves(G,cut_off_number):\n",
    "    \n",
    "    reverse_dict = {\n",
    "    \"up\": \"down\",\n",
    "    \"down\": \"up\",\n",
    "    \"north\": \"south\",\n",
    "    \"south\": \"north\",\n",
    "    \"east\": \"west\",\n",
    "    \"west\": \"east\",\n",
    "    \"northeast\": \"southwest\",\n",
    "    \"northwest\": \"southeast\",\n",
    "    \"southeast\": \"northwest\",\n",
    "    \"southwest\": \"northeast\"\n",
    "}\n",
    "    \n",
    "    edges=get_edegs(G)\n",
    "    actions=set()\n",
    "    for edge in edges:\n",
    "        if edge[2]['step_min_cutoff']<=cut_off_number:\n",
    "            if edge[2]['action'] not in reverse_dict.keys():\n",
    "                actions.add(edge[2]['action'])\n",
    "    return len(actions)\n",
    "\n",
    "def num_of_tokens_per_edge(G,cut_off_number,token_num):\n",
    "    return token_num/num_of_exp_edges(G,cut_off_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be01f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_map(map_dir,game_name):\n",
    "    G_eval,G,actions,locations,all2all,all_pairs,walkthrough=get_game_info_with_G_eval(map_dir,game_name)\n",
    "    cut_off_number,token_num=get_cut_off_and_walkthrough_text(walkthrough)\n",
    "    \n",
    "    result = {\n",
    "        'num_of_locations': num_of_locations(G, cut_off_number),\n",
    "        'num_of_exp_edges': num_of_exp_edges(G, cut_off_number),\n",
    "        'num_of_imp_edges': num_of_imp_edges(G, cut_off_number),\n",
    "#         'ratio_of_conf_locations': ratio_of_conf_locations(G,all2all, cut_off_number),\n",
    "        'num_of_conf_locations':num_of_conf_locations(G,all2all, cut_off_number),\n",
    "#         'avg_len_of_all2all': average_length_of_all2all(all2all, cut_off_number),\n",
    "        'avg_len_easy': average_length_of_all2all_simple(all2all, cut_off_number),\n",
    "        'avg_len_hard': average_length_of_all2all_hard(all2all, cut_off_number),\n",
    "        'ave_num_of_imp_in_hard': average_num_of_imp_edge(all2all, cut_off_number),\n",
    "        'num_of_special_moves': num_of_special_moves(G, cut_off_number),\n",
    "        'avg_len_scene': num_of_tokens_per_edge(G, cut_off_number, token_num)\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def get_data(model_name,difficulty,map_dir,result_dir):\n",
    "    for root, dirs, files in os.walk(result_dir):\n",
    "        if root.endswith(model_name):\n",
    "            for task in dirs:\n",
    "                path=osp.join(root,task)\n",
    "                for file in os.listdir(path):\n",
    "                    if difficulty in file:\n",
    "                        if task=='pathgen':\n",
    "                            rf_df = pd.read_csv(os.path.join(path, file))\n",
    "                        else:\n",
    "                            df_df = pd.read_csv(os.path.join(path, file))\n",
    "                        print(os.path.join(path, file))\n",
    "    df_dict=df_df[:-2].to_dict()\n",
    "    rf_dict=rf_df[:-2].to_dict()\n",
    "\n",
    "    rst={}\n",
    "    for k,v in df_dict['name'].items():\n",
    "        rst[v]={\n",
    "            'df_easy_success_rate':df_dict['easy_success_rate'][k],\n",
    "            'df_hard_success_rate':df_dict['hard_success_rate'][k]\n",
    "        }\n",
    "\n",
    "    for k,v in rf_dict['name'].items():\n",
    "        rst[v]['rf_easy_success_rate']=rf_dict['easy_success_rate'][k]\n",
    "        rst[v]['rf_hard_success_rate']=rf_dict['hard_success_rate'][k]\n",
    "\n",
    "    for key in rst.keys():\n",
    "        rst[key].update(analyze_map(map_dir,key))\n",
    "        \n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90419c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/data/mei-work/kangrui/github/mango/kangrui/eval_results/results_gpt_overall_0709/gpt-4/pathgen/sorted_result_loose_2023-07-10-02-35-11_760.csv\n",
      "/share/data/mei-work/kangrui/github/mango/kangrui/eval_results/results_gpt_overall_0709/gpt-4/stepnav/sorted_result_loose_2023-07-10-02-34-11_399.csv\n",
      "/share/data/mei-work/kangrui/github/mango/kangrui/eval_results/results_gpt_overall_0709/gpt-3.5-turbo/pathgen/sorted_result_loose_2023-07-10-02-38-26_138.csv\n",
      "/share/data/mei-work/kangrui/github/mango/kangrui/eval_results/results_gpt_overall_0709/gpt-3.5-turbo/stepnav/sorted_result_loose_2023-07-10-02-36-53_691.csv\n"
     ]
    }
   ],
   "source": [
    "# note book input\n",
    "difficulty='loose'\n",
    "map_dir=f\"/share/data/mei-work/kangrui/github/mango/data/\"\n",
    "result_dir=f\"/share/data/mei-work/kangrui/github/mango/kangrui/eval_results/results_gpt_overall_0709\"\n",
    "\n",
    "final_result={'gpt-4':{},'gpt-3.5-turbo':{}}\n",
    "\n",
    "for model_name in ['gpt-4','gpt-3.5-turbo']:\n",
    "    final_result[model_name]=get_data(model_name,difficulty,map_dir,result_dir)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e8733711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_beta_pvalue(x, y):\n",
    "    # Ensure lists are numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Add a constant (intercept term) to predictors\n",
    "    X = sm.add_constant(x)\n",
    "\n",
    "    # Fit ordinary least squares regression\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Get slope (beta) and p-value\n",
    "    beta = results.params[1]\n",
    "    p_value = results.pvalues[1]\n",
    "\n",
    "    return beta, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71e0dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_list={'gpt-4':[],'gpt-3.5-turbo':[]}\n",
    "for model_name in ['gpt-4','gpt-3.5-turbo']:\n",
    "    rst_list=[]\n",
    "    for k,v in final_result[model_name].items():\n",
    "        rst_list.append(v)\n",
    "    final_result_list[model_name]=rst_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5131e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_easy_success_rate': 1.0,\n",
       " 'df_hard_success_rate': 1.0,\n",
       " 'rf_easy_success_rate': 1.0,\n",
       " 'rf_hard_success_rate': 1.0,\n",
       " 'num_of_locations': 5,\n",
       " 'num_of_exp_edges': 5,\n",
       " 'num_of_imp_edges': 2,\n",
       " 'num_of_conf_locations': 0.0,\n",
       " 'avg_len_easy': 1.9090909090909092,\n",
       " 'avg_len_hard': 1.8,\n",
       " 'ave_num_of_imp_in_hard': 1.4,\n",
       " 'num_of_special_moves': 1,\n",
       " 'avg_len_scene': 258.2}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_list['gpt-4'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6114617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cov\n",
    "# calculate for RF_HARD\n",
    "    \n",
    "    \n",
    "# df = pd.DataFrame(rst_list)\n",
    "# df_RF_HARD = df.drop(columns=['rf_hard_success_rate','df_easy_success_rate',\n",
    "#                               'df_hard_success_rate','rf_easy_success_rate',]\n",
    "# df_RF_HARD = df_RF_HARD.dropna()\n",
    "# df_RF_HARD_standardized = (df_RF_HARD - df_RF_HARD.mean()) / df_RF_HARD.std()\n",
    "# cov_matrix = df_RF_HARD_standardized.cov()\n",
    "# print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "892061f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-linear\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from scipy import stats\n",
    "# y=df['rf_hard_success_rate']\n",
    "# X=df_RF_HARD_standardized\n",
    "# X = sm.add_constant(X)\n",
    "\n",
    "# # Fit ordinary least squares regression\n",
    "# model = sm.OLS(y, X)\n",
    "# results = model.fit()\n",
    "\n",
    "# # Get slope (beta) and p-value\n",
    "# # beta = results.params[1]\n",
    "# # p_value = results.pvalues[1]\n",
    "\n",
    "# print(results.pvalues)\n",
    "# print(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96e8210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA()\n",
    "# pca.fit(df_RF_HARD_standardized)\n",
    "\n",
    "# # Get the eigenvalues (explained variance)\n",
    "# eigenvalues = pca.explained_variance_\n",
    "# print(\"\\nEigenvalues (Explained Variance): \")\n",
    "# print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da72353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvectors = pca.components_\n",
    "# feature_names = df_RF_HARD_standardized.columns\n",
    "\n",
    "# print(\"Eigenvectors (Principal Components):\")\n",
    "# for i, eigenvector in enumerate(eigenvectors):\n",
    "#     print(f\"\\nPrincipal Component {i+1}:\")\n",
    "#     for feature_weight, feature_name in zip(eigenvector, feature_names):\n",
    "#         print(f\"{feature_name}: {feature_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fcc46aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average\n",
    "\n",
    "# keys = rst_list[0].keys()\n",
    "# total = {key: 0 for key in keys}\n",
    "\n",
    "# # loop over the list to sum up the values for each key\n",
    "# for dictionary in rst_list:\n",
    "#     for key in keys:\n",
    "#         total[key] += dictionary[key]\n",
    "\n",
    "# # calculate the average for each key\n",
    "# average = {key: total_value / len(rst_list) for key, total_value in total.items()}\n",
    "\n",
    "# average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f95d6883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_of_locations': 6,\n",
       " 'num_of_exp_edges': 6,\n",
       " 'num_of_imp_edges': 3,\n",
       " 'num_of_conf_locations': 1.5,\n",
       " 'avg_len_easy': 2.0,\n",
       " 'avg_len_hard': 1.8888888888888888,\n",
       " 'ave_num_of_imp_in_hard': 1.5555555555555556,\n",
       " 'num_of_special_moves': 0,\n",
       " 'avg_len_scene': 579.3333333333334}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_map(map_dir,'lostpig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2403764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_list):\n",
    "    y_vars = ['df_easy_success_rate', 'df_hard_success_rate', 'rf_easy_success_rate', 'rf_hard_success_rate']\n",
    "    x_vars = [key for key in data_list[0].keys() if key not in y_vars]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for y_var in y_vars:\n",
    "        results[y_var] = {}\n",
    "        for x_var in x_vars:\n",
    "            x_values = np.array([d[x_var] for d in data_list])\n",
    "            y_values = np.array([d[y_var] for d in data_list])\n",
    "            \n",
    "            # Identify indices where either x or y values are NaN\n",
    "            nan_indices = np.isnan(x_values) | np.isnan(y_values)\n",
    "\n",
    "            # Remove elements with these indices\n",
    "            x_values = x_values[~nan_indices]\n",
    "            \n",
    "            mu=np.mean(x_values,axis=0)\n",
    "            sigma=np.std(x_values,axis=0)\n",
    "            x_values=(x_values-mu)/sigma\n",
    "            \n",
    "            y_values = y_values[~nan_indices]\n",
    "            \n",
    "            beta, p_value = calculate_beta_pvalue(x_values, y_values)\n",
    "            results[y_var][x_var] = {'beta': beta, 'p-value': p_value}\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b49da37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_result={'gpt-4':process_data(final_result_list['gpt-4']),\n",
    "            'gpt-3.5-turbo':process_data(final_result_list['gpt-3.5-turbo'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cf7f8bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_locations {'beta': -0.12016535494827207, 'p-value': 0.00011598685869870894}\n",
      "num_of_exp_edges {'beta': -0.09559628329754738, 'p-value': 0.0028792092769139546}\n",
      "num_of_imp_edges {'beta': -0.08822720385054866, 'p-value': 0.006298238360291655}\n",
      "num_of_conf_locations {'beta': -0.08827252318194721, 'p-value': 0.006269385869155417}\n",
      "avg_len_easy {'beta': -0.1314709071766833, 'p-value': 1.808583062434654e-05}\n",
      "avg_len_hard {'beta': -0.0739060025739398, 'p-value': 0.023666100699843016}\n",
      "ave_num_of_imp_in_hard {'beta': -0.061741559755436166, 'p-value': 0.06074136012874523}\n",
      "num_of_special_moves {'beta': -0.0993091348756164, 'p-value': 0.0018857829834572162}\n",
      "avg_len_scene {'beta': 0.0690154145299896, 'p-value': 0.03522679377845401}\n"
     ]
    }
   ],
   "source": [
    "for k,v in reg_result['gpt-4']['rf_easy_success_rate'].items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "259cd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard={'gpt-4':{'df_hard_success_rate':reg_result['gpt-4']['df_hard_success_rate'],\n",
    "              'rf_hard_success_rate':reg_result['gpt-4']['rf_hard_success_rate'],},\n",
    "     'gpt-3.5-turbo':{'df_hard_success_rate':reg_result['gpt-3.5-turbo']['df_hard_success_rate'],\n",
    "                     'rf_hard_success_rate':reg_result['gpt-3.5-turbo']['rf_hard_success_rate'],}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b230b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt-4': {'df_hard_success_rate': {'num_of_locations': {'beta': -0.08341181513601865, 'p-value': 0.006811663409619938}, 'num_of_exp_edges': {'beta': -0.0800395365099226, 'p-value': 0.009713516143594897}, 'num_of_imp_edges': {'beta': -0.11763945823293881, 'p-value': 5.348549384740426e-05}, 'num_of_conf_locations': {'beta': -0.0680822117973976, 'p-value': 0.029892682274400055}, 'avg_len_easy': {'beta': -0.06845454206293565, 'p-value': 0.028949562718192934}, 'avg_len_hard': {'beta': -0.09408821810801356, 'p-value': 0.0019540757561536887}, 'ave_num_of_imp_in_hard': {'beta': -0.08076441561731834, 'p-value': 0.009013545231994258}, 'num_of_special_moves': {'beta': 0.01349843491951645, 'p-value': 0.6760845527924433}, 'avg_len_scene': {'beta': 0.08384271728695326, 'p-value': 0.006501256593029141}}, 'rf_hard_success_rate': {'num_of_locations': {'beta': -0.11454375361064521, 'p-value': 0.006459108102809318}, 'num_of_exp_edges': {'beta': -0.10711085775998438, 'p-value': 0.011374659742625207}, 'num_of_imp_edges': {'beta': -0.1522652829600909, 'p-value': 0.00016138923173525486}, 'num_of_conf_locations': {'beta': -0.08068320434514492, 'p-value': 0.06113885138685457}, 'avg_len_easy': {'beta': -0.09940099567666098, 'p-value': 0.019544102537155224}, 'avg_len_hard': {'beta': -0.12195370792409557, 'p-value': 0.0035069696787041926}, 'ave_num_of_imp_in_hard': {'beta': -0.09630773319019303, 'p-value': 0.02398758052628161}, 'num_of_special_moves': {'beta': 0.01975503052701867, 'p-value': 0.6534033743492551}, 'avg_len_scene': {'beta': 0.10486736887353085, 'p-value': 0.013377046534310483}}}, 'gpt-3.5-turbo': {'df_hard_success_rate': {'num_of_locations': {'beta': -0.0492862131741472, 'p-value': 0.08819625418316111}, 'num_of_exp_edges': {'beta': -0.05231892834743244, 'p-value': 0.0696001040194004}, 'num_of_imp_edges': {'beta': -0.05949898643918661, 'p-value': 0.037761575783571776}, 'num_of_conf_locations': {'beta': -0.044505118273081214, 'p-value': 0.1250358572424658}, 'avg_len_easy': {'beta': -0.053969651773618, 'p-value': 0.06086421609187041}, 'avg_len_hard': {'beta': -0.07161942229007869, 'p-value': 0.011235280210473835}, 'ave_num_of_imp_in_hard': {'beta': -0.05737411392956539, 'p-value': 0.04560290234923469}, 'num_of_special_moves': {'beta': 0.01162203870482069, 'p-value': 0.6930078262820223}, 'avg_len_scene': {'beta': 0.032348929976900094, 'p-value': 0.2684338827189908}}, 'rf_hard_success_rate': {'num_of_locations': {'beta': -0.055355816854876394, 'p-value': 0.042683604025716755}, 'num_of_exp_edges': {'beta': -0.06394128573128652, 'p-value': 0.018143462319162956}, 'num_of_imp_edges': {'beta': -0.03183787626033672, 'p-value': 0.25202001687558384}, 'num_of_conf_locations': {'beta': -0.05539949977244217, 'p-value': 0.04251142150074377}, 'avg_len_easy': {'beta': -0.05142666937709698, 'p-value': 0.060650888519602174}, 'avg_len_hard': {'beta': -0.05454801775796899, 'p-value': 0.04597118415080587}, 'ave_num_of_imp_in_hard': {'beta': -0.022149040017861377, 'p-value': 0.4275179422874924}, 'num_of_special_moves': {'beta': 0.059895116333467474, 'p-value': 0.02758081410549217}, 'avg_len_scene': {'beta': 0.04993356832164265, 'p-value': 0.06888492531419499}}}}\n"
     ]
    }
   ],
   "source": [
    "print(hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "562858d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_easy_success_rate num_of_conf_locations {'beta': -0.018053814619060516, 'p-value': 0.017034688367336917}\n",
      "df_hard_success_rate num_of_conf_locations {'beta': -0.01324795427531114, 'p-value': 0.12503585724246571}\n",
      "rf_easy_success_rate num_of_conf_locations {'beta': -0.021445333987439336, 'p-value': 0.006012165237880988}\n",
      "rf_hard_success_rate num_of_conf_locations {'beta': -0.016661551285832715, 'p-value': 0.042511421500743614}\n"
     ]
    }
   ],
   "source": [
    "for k, v in final_rst.items():\n",
    "    for kk,vv in v.items():\n",
    "        if kk=='num_of_conf_locations':\n",
    "            print(k,kk,vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "abe0f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in final_rst.items():\n",
    "#      for kk,vv in v.items():\n",
    "#         if kk=='num_of_conf_locations':\n",
    "#             print(k,kk,vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e32b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mango",
   "language": "python",
   "name": "mango"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
